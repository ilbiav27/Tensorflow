{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.io import imshow\n",
    "from datetime import datetime\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "import vgg16\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_num = 1664 #The number of image data\n",
    "batch_num = math.ceil(image_num/batch_size)\n",
    "sample_size = 3\n",
    "epoch_num = 1000\n",
    "classes_num = 5\n",
    "MOVING_AVERAGE_DECAY = 0.9999\n",
    "\n",
    "ckpt_loc = 'TL_ckpt' \n",
    "eval_loc = 'eval_dir'\n",
    "data_loc = 'hanseul'\n",
    "\n",
    "dictionary = {'사람':0,'고양이':1,'강아지':2,'차':3,'배':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(ckpt_loc):\n",
    "    os.mkdir(ckpt_loc)\n",
    "if not os.path.isdir(eval_loc):\n",
    "    os.mkdir(eval_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hanseul_data.txt','r') as f:\n",
    "    lines = f.readlines() #line[:-3] : image_name line[-2:-1] : image_label\n",
    "    \n",
    "image = np.ndarray([image_num,224,224,3])\n",
    "label = np.ndarray([image_num])\n",
    "\n",
    "i = 0\n",
    "for line in lines:\n",
    "    if i == image_num: break\n",
    "    label[i] = np.asanyarray(int(line[-2:-1])).reshape([1])\n",
    "    image[i] = np.asanyarray(Image.open(line[:-3])).reshape([1,224,224,3])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program is started\n",
      "C:\\Users\\koo\\jupyterNotebook\\Transfer Learning\\vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 3s\n",
      " Running starts!\n",
      "[ 2018-07-25 18:03:06.917768  1 epoch] loss : 122985.4519 accuracy : 0.819111\n",
      "[ 2018-07-25 18:03:31.507175  2 epoch] loss : 3904.9838 accuracy : 0.984375\n",
      "[ 2018-07-25 18:03:46.462030  3 epoch] loss : 1188.6663 accuracy : 0.996394\n",
      "[ 2018-07-25 18:04:01.415885  4 epoch] loss : 75.8933 accuracy : 0.999399\n",
      "[ 2018-07-25 18:04:16.368741  5 epoch] loss :  0.0000 accuracy : 1.000000\n",
      "[ 2018-07-25 18:04:31.330596  6 epoch] loss :  0.0000 accuracy : 1.000000\n",
      "[ 2018-07-25 18:04:46.284452  7 epoch] loss :  0.0000 accuracy : 1.000000\n",
      "[ 2018-07-25 18:05:01.261308  8 epoch] loss :  0.0000 accuracy : 1.000000\n",
      "[ 2018-07-25 18:05:16.217164  9 epoch] loss :  0.0000 accuracy : 1.000000\n",
      "[ 2018-07-25 18:05:31.200021 10 epoch] loss :  0.0000 accuracy : 1.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=(tf.GPUOptions(per_process_gpu_memory_fraction=0.6)))) as sess:\n",
    "        #For saving checkpoint\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(ckpt_loc)\n",
    "\n",
    "        print('program is started')\n",
    "        images = tf.placeholder(\"float32\", [None, 224, 224, 3],name = 'images')\n",
    "        labels = tf.placeholder(\"int64\",[None], name = 'labels')\n",
    "\n",
    "        figure = plt.figure(figsize=(20,sample_size))\n",
    "        vgg = vgg16.Vgg16(fig = figure)\n",
    " \n",
    "        with tf.name_scope(\"content_vgg\"):\n",
    "            vgg.build(images,labels)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            filter_img = tf.summary.FileWriter('filter',sess.graph)\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            start = datetime.now()\n",
    "            print(' Running starts!')\n",
    "            \n",
    "            for epoch in range(epoch_num):\n",
    "                img_count=0\n",
    "                loss_sum = 0.0\n",
    "                acc_sum = 0.0 \n",
    "                \n",
    "                for batch in range(batch_num):\n",
    "                    feed_dict = {images: image[img_count:img_count+batch_size], labels: label[img_count:img_count+batch_size]}\n",
    "\n",
    "                    loss, train, acc = sess.run([vgg.cost, vgg.train, vgg.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "                    img_count += batch_size\n",
    "                    global_step = img_count + image_num*(epoch+1)\n",
    "                    \n",
    "                    loss_sum +=  loss\n",
    "                    acc_sum += acc\n",
    "                    \n",
    "                loss = np.sum(loss_sum)/batch_num\n",
    "                acc = np.sum(acc_sum)/batch_num\n",
    "                \n",
    "                print('[',datetime.now(),\"%2d\" %(epoch+1),\"epoch] loss : %7.4f\" % loss, \"accuracy : %.6f\" % acc)\n",
    "                \n",
    "                if epoch % 10 == 0:\n",
    "                    saver.save(sess,os.path.join(ckpt_loc,\"TL-model\"),global_step = global_step) #write_meta_graph=False meta 원하지 않음\n",
    "\n",
    "            print(datetime.now(),' Running finished!')\n",
    "            print('-img.close')\n",
    "            filter_img.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
